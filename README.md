# ðŸ“‘ LLM-Powered Table QA from PDFs

An end-to-end pipeline that extracts **tabular data from institutional PDFs** (scanned + digital), segments them by headings, and enables **zero-shot question answering** on the tables using **NVIDIAâ€™s Nemotron-253B LLM** via an OpenAI-compatible API.

---

## ðŸš€ Project Overview
Institutional reports (like **NIRF submissions**) often come as **large, messy PDFs** with both scanned and digital content. Extracting structured tabular data from them is challenging.  

This project combines:
1. **Rule-based PDF parsing + OCR** â†’ Detect headings, chunk PDFs into structured dictionaries.  
2. **LLM-powered QA** â†’ Query tables directly with natural language (e.g., *â€œHow many regular faculty does the institution have?â€*).  
3. **Zero-shot inference** â†’ No fine-tuning or embeddings; answers are extracted via carefully designed prompts.  

---

## ðŸ—ï¸ Architecture & Workflow
```mermaid
flowchart TD
    A[Input PDF] --> B[PDF Text Extraction - PyMuPDF + OCR]
    B --> C[Heading Detection - Font/Size/Bold Rules]
    C --> D[Chunking into Table Dictionary]
    D --> E[Stringify Tables for LLM]
    E --> F[ZeroShotLLM Wrapper - Nemotron 253B API]
    F --> G[Clean Answer]
